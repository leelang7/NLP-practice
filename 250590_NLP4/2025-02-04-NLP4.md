## 1. KoNLPy를 통한 한국어 전처리

`KoNLPy`는 한국어 형태소 사전을 기반으로 한국어 단어를 추출해 주는 파이썬 라이브러리입니다.

이번 실습에서는 `KoNLPy`를 사용하여 한국어 문장 간 유사도 측정용 데이터셋인 `KorSTS` 데이터셋을 전처리하도록 하겠습니다.

## 지시사항

1. 변수 `sent`에는 `sts-train.tsv`파일에 저장되어 있는 `KorSTS` 데이터셋이 들어있습니다. 첫 5개 문장을 확인하세요.
2. 꼬꼬마 형태소 사전(`Kkma`)을 사용해서 변수 `sent` 내 **모든 문장의 명사**를 `nouns` 리스트에 저장하세요.
3. Open Korean Text 형태소 사전(`Okt`)을 사용하여 변수 `sent` 내 각 문장의 형태소 분석의 결과를 `pos_results` 리스트에 저장하세요.
4. 형태소 분석이 수행된 `sent`의 두 번째 문장의 분석 결과를 확인해보세요. 변수 `sent`에 stemming 기반 형태소 분석을 적용하여 `sent`의 **두 번째 문장**을 `stem_pos_results` 변수에 저장하세요.



## 2. soynlp를 통한 한국어 전처리

`soynlp`는 한국어 단어 추출 중 발생할 수 있는 미등록 단어 문제를 해결할 수 있는 전처리 라이브러리입니다. `soynlp`는 학습 데이터에서 자주 발생하는 패턴을 기반으로 단어의 경계선을 구분하여 단어를 추출합니다.

이번 실습에서는 신문 기사를 학습 데이터로 사용하여 명사 목록을 학습한 뒤, 주어진 문장에서 명사를 추출할 예정입니다.

## 지시사항

1. 학습에 사용할 신문 기사는 `articles.txt`에 저장되어 있습니다. 실습을 위해 내용은 이미 `train_data`에 저장되어 있습니다. 실행 버튼을 눌러 학습 문서의 개수를 확인하세요.
2. 명사 추출을 위해 `LRNounExtractor_v2` 객체를 생성하세요.
3. 생성한 `LRNounExtractor_v2` 객체를 `train_data`로 학습을 진행한 뒤 생성된 명사 목록을 `nouns` 변수에 저장하세요.
4. 생성된 명사 목록을 사용해서 문장이 들어있는 `sent`에서 명사를 추출해 `sent_nouns` 리스트에 저장하세요.



## 3. 자카드 지수를 통한 문장 유사도 측정

자카드 지수는 두 문장 간 공통된 단어의 비율로 문장 간 유사도를 측정합니다. 이번 실습에서는 직접 자카드 지수를 계산하는 `cal_jaccard_sim`함수를 구현하고, `nltk`에서 이미 구현된 자카드 거리 함수와 비교해 볼 예정입니다.

## 지시사항

1. 함수 `cal_jaccard_sim`에서 입력으로 받아오는 두 문장 `sent1`, `sent2`를 각각 단어 기준으로 분리(토큰화)하세요. 그리고 결과를 `set` 타입으로 변환하세요.
2. 두 문장에서 **공통된 단어의 개수**를 세어주는 부분을 완성해주세요. `set` 객체의 공통된 부분을 찾아주는 파이썬 자체 함수인 `intersection()`을 사용하세요.
3. 여러 `set` 내 발생하는 전체 항목의 개수를 계산해주는 `union()` 함수를 사용하여 두 문장 내 발생하는 **모든 단어의 개수**를 세어주는 부분을 완성하세요.
4. 계산된 자카드 지수를 `return`에 넣어 반환하세요. 반환 시, 데이터 타입을 `float`으로 변환하세요.
5. 작성된 `cal_jaccard_sim()` 함수를 사용하여, 변수 `sen_1`, `sen_2`에 주어진 문장 간 자카드 유사도를 확인해봅니다.
6. 결과 비교를 위해, `nltk`의 **자카드 거리**를 계산해 주는 `jaccard_distance(w1, w2)`를 이용해 `sent_1`, `sent_2`의 자카드 유사도를 계산하여 `nltk_jaccard_sim` 변수에 저장하세요.
   - `jaccard_distance(w1, w2)`에 인자로 들어가는 `w1`, `w2`는 `set` 타입으로 정의된 각 문장별 단어 목록입니다.
   - 유사도와 거리는 다음과 같은 관계로 정의가 됩니다: **유사도 = 1 - 거리**



## 4. 코사인 유사도를 통한 문장 유사도 측정

코사인 유사도는 두 벡터 간의 각도를 사용하여 유사도를 측정합니다. 이번 실습에서는 직접 코사인 유사도를 계산하는 `cal_cosine_sim`함수를 구현하고, `scipy`와 `scikit-learn`에서 이미 구현된 코사인 거리 함수와 비교해 볼 예정입니다.

## 지시사항

1. 매개변수로 입력되는 벡터 `v1`, `v2` 간 코사인 유사도를 계산해 주는 `cal_cosine_sim()` 함수를 완성하세요.
   - 벡터 간 내적은 `numpy`의 `dot()`함수를, 루트는 `numpy`의 `sqrt()`함수를 사용합니다.
   - 벡터 `v1`의 크기는 `dot(v1, v1)`의 루트값으로 계산할 수 있습니다.
2. 1번에서 완성된 함수를 사용하여, `sent_1`과 `sent_2`의 **코사인 유사도**를 확인해 봅니다.
3. `scipy`의 `distance.cosine`함수를 사용하여 다시 한번 `sent_1`과 `sent_2`의 **코사인 유사도**를 계산하고, `scipy_cosine_sim` 변수에 저장하세요.
   - `distance.cosine()`은 코사인 거리를 계산하기 때문에 **유사도 = 1 - 거리** 관계를 사용해서 유사도로 변환해 주시길 바랍니다.
4. `scikit-learn`의 `pairwise.cosine_similarity()` 함수 매개변수를 변수 `all_sent`로 설정하고, 결과를 `scikit_learn_cosine_sim` 변수에 저장하세요.